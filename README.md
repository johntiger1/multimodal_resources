# multimodal_resources
A bigger thread is the healthcare setting: as it turns out, the *best* datasets, are indeed publicly available health datasets only! Note that we do not have other great resources for multi-modality! This motivates why we must do it in the healthcare space

Resources for exploring multimodality  

Pretty much just this site: https://physionet.org/content/

But also, links like the following:

https://physionet.org/content/widsdatathon2020/1.0.0/
Chest x-rays + text: https://physionet.org/content/mimic-cxr/2.0.0/

GQA: has scene graphs, visuals (images) and text (questions):
https://cs.stanford.edu/people/dorarad/gqa/download.html

But it is hard to infer gender/protected attributes? Perhaps not! If we can ask the general question, then we have a noisy label! And we can investigate fairness in this context!
